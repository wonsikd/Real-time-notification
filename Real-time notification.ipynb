{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIg389ufAJ7K"
   },
   "source": [
    "### 본 프로젝트는 보유 종목에 대한 실시간 공시 및 뉴스를 가져올 수 있게한 프로그램입니다.\n",
    "### 파일은 '국내펀드보유내역.xlsx'와 같은 양식을 지닌 파일이 있으면 작동이 가능합니다.\n",
    "### 회사에서 사용한 프로그램이므로 회사 엑셀파일의 양식에 맞추느라 직접 사용하실 경우 약간의 수정이 필요합니다.(해당 양식은 capital IQ 양식입니다.)\n",
    "### 실제 사용하실 경우, get_corp_list(self) 함수에서 data1,data2,data3 를 수정하셔야합니다.\n",
    "### 회사의 니즈를 맞춰 양식 및 필요한 공시를 가져오기 위해 조건이 다소 일반적이지 않음은 양해부탁드립니다.\n",
    "### 전체적인 알고리즘은 다음과 같습니다.\n",
    "\n",
    "1. class 실행\n",
    "2. 보유종목 엑셀파일을 열어 종목 저장 및 종목에 따른 업종 딕셔너리 생성\n",
    "3. 보유종목에 따라 하나씩 dart에서 공시를 가져옵니다.\n",
    "4. 이후 공시를 전부 가져오면, 네이버 실시간 뉴스를 가져옵니다.(중복뉴스 및 유사 뉴스는 임베딩을 통해 유사도를 측정 후 제거해주었습니다.)\n",
    "5. 3-4과정을 프로그램이 꺼지지 않는 한 계속 반복합니다. 과부하를 막기위해 sleep을 걸어줘 240초 마다 서칭을 하게끔 해주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1657253511393,
     "user": {
      "displayName": "윤원식",
      "userId": "02047733601976023238"
     },
     "user_tz": -540
    },
    "id": "R1JfOzL35m-8"
   },
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dart_fss.corp import corp_list\n",
    "from selenium import webdriver\n",
    "\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dart_fss as dart\n",
    "import time\n",
    "#from plyer import notification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "news_dict={}\n",
    "report_code = []\n",
    "\n",
    "chrome_path = \"C://Users\\master//PycharmProjects//chromedriver.exe\"\n",
    "api_key = '' #api 키는 개인이 직접 받아와야합니다.\n",
    "\n",
    "class searching_reports(): #클래스를 시작하면 먼저 공시를 가져오기 시작합니다. 이후 공시를 다 가지고 오면, 보유종목들의 실시간 뉴스를 가져오게끔 하였습니다.\n",
    "    def __init__(self):\n",
    "\n",
    "        self.last_dict={}\n",
    "        global news_dict\n",
    "        global chrome_path\n",
    "        self.news_dict=news_dict\n",
    "\n",
    "        self.get_corp_list() # 종목에 따른 업종 가져오는 함수\n",
    "        #searching_reports().get_corp_list()\n",
    "\n",
    "        report_code_old = {}\n",
    "\n",
    "        while True:\n",
    "\n",
    "            self.get_reports_list()\n",
    "\n",
    "            for i in range(len(report_name)): #루프 반복\n",
    "                if list(report_code.keys())[i] not in report_code_old.keys():\n",
    "\n",
    "                    k=\"%s :: %s 공시가 올라왔습니다.\" % (report_code.get(list(report_code.keys())[i]), report_name.get(list(report_code.keys())[i]))\n",
    "                    print(k)\n",
    "\n",
    "            report_code_old = report_code\n",
    "\n",
    "\n",
    "            ############################### 뉴스 가져오기 시작하는 코드\n",
    "            for roop in range(5):\n",
    "                self.last_dict = self.news_dict\n",
    "                self.news_dict = news( corp=corp_list, news_dict=self.news_dict,chrome_path)\n",
    "                # print(\"전종목을 검색 완료하였습니다.\")\n",
    "                if self.last_dict.values() != news_dict.values():\n",
    "                    for i in self.news_dict.keys():\n",
    "\n",
    "                        if i not in self.last_dict.keys():\n",
    "                            print(news_dict[i])\n",
    "                        else:\n",
    "                            if self.last_dict[i] != self.news_dict[i]:\n",
    "                                print(self.news_dict[i])\n",
    "\n",
    "            time.sleep(240)\n",
    "\n",
    "                # print(\"last_dict 갱신화 완료\")\n",
    "                # time.sleep()\n",
    "\n",
    "\n",
    "    def get_corp_list(self): #업종에 대한 딕셔너리 생성 -> 공시에서 특정 업종의 공시는 불필요하게 자주 나오는 공시는 제거하기 위해 업종을 딕셔너리에 담아줬습니다. 모든 공시를 가져오려면 불필요합니다.\n",
    "\n",
    "        global corp_list\n",
    "\n",
    "        data_1 = pd.read_excel('국내펀드보유종목내역.xlsx', sheet_name='2010', usecols=['종목명', '업종'])\n",
    "        data_2 = pd.read_excel('국내펀드보유종목내역.xlsx', sheet_name='5220', usecols=['종목명', '업종'])\n",
    "        data_3 = pd.read_excel('국내펀드보유종목내역.xlsx', sheet_name='5230', usecols=['종목명', '업종'])\n",
    "\n",
    "        corp_list = dict()\n",
    "\n",
    "        for i in range(0, len(data_1) - 1):\n",
    "            corp_list[data_1['종목명'][i]] = data_1['업종'][i]\n",
    "\n",
    "        for i in range(0, len(data_2) - 1):\n",
    "            corp_list[data_2['종목명'][i]] = data_2['업종'][i]\n",
    "\n",
    "        for i in range(0, len(data_3) - 1):\n",
    "            corp_list[data_2['종목명'][i]] = data_2['업종'][i]\n",
    "\n",
    "\n",
    "    def get_reports_list(self):\n",
    "\n",
    "\n",
    "        global api_key\n",
    "\n",
    "        dart.set_api_key(api_key=api_key)\n",
    "\n",
    "        detail_index = [\"A001\", \"A002\", \"A003\", \"B001\", \"B002\", \"B003\", \"C001\", \"C002\", \"C003\", \"C004\", \"C005\", \"C006\",\n",
    "                        \"C007\", \"C008\",\n",
    "                        \"C009\", \"C010\", \"D001\", \"D002\", \"D004\", \"E001\", \"E003\", \"E004\", \"E008\", \"I001\", \"I002\", \"I003\",\n",
    "                        \"I004\", \"I005\", \"I006\"]\n",
    "\n",
    "        detail_index_fin = [\"A001\", \"A002\", \"A003\", \"B001\", \"B002\", \"B003\",\n",
    "                            \"D001\", \"D002\", \"D004\", \"E001\", \"E003\", \"E004\", \"E008\", \"I001\", \"I002\",\n",
    "                            \"I003\", \"I004\", \"I005\", \"I006\"]\n",
    "\n",
    "        reports_whole = dart.filings.search(page_count=100, pblntf_detail_ty=detail_index)\n",
    "        for j in range(1, reports_whole.total_page + 1):\n",
    "            reports = dart.filings.search(page_count=100, pblntf_detail_ty=detail_index, page_no=j)\n",
    "\n",
    "            length_reports = len(reports.report_list)\n",
    "\n",
    "            corp_dict = {}\n",
    "            report_code = {}\n",
    "            report_name = {}\n",
    "\n",
    "        for j in range(1, reports_whole.total_page + 1):\n",
    "            reports = dart.filings.search(page_count=100, pblntf_detail_ty=detail_index, page_no=j)\n",
    "\n",
    "            length_reports = len(reports.report_list)\n",
    "\n",
    "            for i in range(0, length_reports):\n",
    "                dict_reports = reports.report_list[i].to_dict()\n",
    "                if dict_reports['corp_name'] in corp_list:\n",
    "\n",
    "                    if corp_list.get(dict_reports['corp_name']) != '증권':\n",
    "                        report_code[dict_reports['rcp_no']] = dict_reports['corp_name']\n",
    "                        corp_dict[dict_reports['corp_name']] = dict_reports['corp_code']\n",
    "                        report_name[dict_reports['rcp_no']] = dict_reports['report_nm']\n",
    "\n",
    "        for j in range(1, reports_whole.total_page + 1):\n",
    "            reports = dart.filings.search(page_count=100, pblntf_detail_ty=detail_index_fin, page_no=j)\n",
    "\n",
    "            length_reports = len(reports.report_list)\n",
    "\n",
    "            fin_dict = {}\n",
    "\n",
    "            for i in range(0, length_reports):\n",
    "                dict_reports = reports.report_list[i].to_dict()\n",
    "\n",
    "                if dict_reports['corp_name'] in corp_list:\n",
    "\n",
    "                    if corp_list.get(dict_reports['corp_name']) == '증권':\n",
    "                        report_code[dict_reports['rcp_no']] = dict_reports['corp_name']\n",
    "                        fin_dict[dict_reports['corp_name']] = dict_reports['corp_code']\n",
    "                        report_name[dict_reports['rcp_no']] = dict_reports['report_nm']\n",
    "\n",
    "        return corp_dict, fin_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def news(corp,news_dict,chrome_path):\n",
    "    # 창 숨기는 옵션 추가\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"headless\")\n",
    "    \n",
    "\n",
    "    driver = webdriver.Chrome(chrome_path,options=options)\n",
    "    corpo = \"이제부터 종목검색을 시작하겠습니다.\"\n",
    "    URL = 'https://search.naver.com/search.naver?where=news&query=' + corpo + '&sm=tab_opt&sort=0&photo=1&field=0&pd=7&docid=&related=0&mynews=0&office_type=0&dupremove=1&office_section_code=0&news_office_checked=&nso=so%3Add%2Cp%3Aall&is_sug_officeid=0'\n",
    "    driver.get(URL)\n",
    "    for corp_1 in corp:\n",
    "        last_news=[]\n",
    "        real_news = []\n",
    "        search = driver.find_element_by_xpath('// *[ @ id = \"nx_query\"]')\n",
    "        search.clear()\n",
    "        search.send_keys(corp_1)\n",
    "        button = driver.find_element_by_xpath('//*[@id=\"nx_search_form\"]/fieldset/button/i')\n",
    "        button.click()\n",
    "        num = len(driver.find_elements_by_css_selector(\".news_tit\"))\n",
    "\n",
    "        if num !=0 and num>4:\n",
    "            #print(corp_1, \"뉴스개수는 %d 개 있습니다.\" % num)\n",
    "            for i in range(1, num+1):\n",
    "\n",
    "                news = driver.find_element_by_xpath('//*[@id=\"main_pack\"]/section/div/div[2]/ul/li[' + str(i) + ']/div[1]/div/a')\n",
    "                news = news.text\n",
    "                news = news.replace(\"'\", \" \")\n",
    "                news = news.replace(\"!\", \" \")\n",
    "                news = news.replace(\".\", \" \")\n",
    "                news = news.replace(\",\", \" \")\n",
    "\n",
    "                news_list = news.split()\n",
    "                # print(news_list)\n",
    "                \n",
    "                if corp_1 not in news_list:\n",
    "                    continue\n",
    "                last_news.append(news) #기업name이 들어간 뉴스기사들\n",
    "\n",
    "            try:\n",
    "                model = SentenceTransformer('paraphrase-distilroberta-base-v1') #임베딩을 하여 중복되거나 유사한 뉴스는 제거되게끔 하였습니다.\n",
    "                embeddings = model.encode(last_news,convert_to_tensor=True)\n",
    "                cosine_scores = util.pytorch_cos_sim(embeddings,embeddings)\n",
    "                \n",
    "                real_news.append(last_news[0])\n",
    "                middle_news_list = []\n",
    "\n",
    "\n",
    "                if corp_1 not in news_dict.keys() :\n",
    "\n",
    "                    for index, i in enumerate(cosine_scores[0].tolist()):\n",
    "                        # print(index,i)\n",
    "                        # print(last_news[index])\n",
    "\n",
    "                        if i < 0.5:\n",
    "                            real_news.append(last_news[index])\n",
    "\n",
    "                    news_dict[corp_1] = real_news\n",
    "                    print(corp_1, \"::\", real_news)\n",
    "                    #print(news_dict)\n",
    "\n",
    "                else:\n",
    "                    for newss in news_dict[corp_1]:\n",
    "                        middle_news_list.append(newss)\n",
    "                        model1 = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "                        embeddings_1 = model.encode(middle_news_list, convert_to_tensor=True)\n",
    "                        cosine_scores_1 = util.pytorch_cos_sim(embeddings_1, embeddings_1)\n",
    "                        for index,i in enumerate(cosine_scores_1[0].tolist()):\n",
    "                            if i<0.5 or i==1:\n",
    "                                #print(corp_1, \"::\", real_news)\n",
    "                                news_dict[corp_1] = middle_news_list\n",
    "\n",
    "                time.sleep(3)\n",
    "\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            #print(news_dict)\n",
    "\n",
    "        else:\n",
    "\n",
    "            search = driver.find_element_by_xpath('// *[ @ id = \"nx_query\"]')\n",
    "            search.clear()\n",
    "            search.send_keys(corp_1)\n",
    "            button = driver.find_element_by_xpath('//*[@id=\"nx_search_form\"]/fieldset/button/i')\n",
    "\n",
    "            button.click()\n",
    "    driver.quit()\n",
    "    #print(news_dict)\n",
    "    return news_dict\n",
    "\n",
    "def call_news(news_dict):\n",
    "    print(news_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22l25PpRKFGC"
   },
   "outputs": [],
   "source": [
    "searching_reports()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPYlP6bwkiiztZ+QNnaRnRt",
   "collapsed_sections": [],
   "name": "Real-time notification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
